{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Analysis of League of Legends Drafts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In the popular video game League of Legends, teams of five face off against each other. Before the game begins, each team picks five unique champions to play. This collection of champions is known as a particular game's draft. \n",
    "\\\n",
    "Each game is also played on a particular patch, a version of the game following biweekly balance changes. Patches through the end of 2024 follow the format `season.patch`, so patch 14.9 would be the ninth patch of the 14th season. \n",
    "\n",
    "This project aims to look at the drafts of professional League of Legends games and use machine learning to train models that are able to predict the winner of a game given each team's draft. \n",
    "\\\n",
    "The results of different models will be compared to each other in order to see what parameters might lead to more accurate results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The data for this project was obtained from [Oracle's Elixir](https://oracleselixir.com/tools/downloads)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model 1**\n",
    "The model for this project was built using PyTorch and encoded through one-hot encoding for the patches and multi-hot encoding for the drafts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Data\n",
    "Since the data currently contains a lot more information than necessary, it must be cleaned in order to present the model with something that is usable in an efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patch         pick1     pick2    pick3   pick4       pick5  result\n",
      "10  13.24       Kalista     Senna  Orianna  Maokai      Aatrox       0\n",
      "11  13.24  Renata Glasc     Varus  LeBlanc    Rell      Rumble       1\n",
      "22  13.24         Neeko  Bel'Veth   Kennen   Senna  Tahm Kench       0\n",
      "23  13.24       Kalista       Jax  LeBlanc    Rell   Jarvan IV       1\n",
      "34  13.24         Neeko   Caitlyn      Lux     Jax    Bel'Veth       1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Josh\\Downloads\\2024_LoL_esports_match_data_from_OraclesElixir.csv', low_memory=False)\n",
    "\n",
    "# Get the rows: 1st row (index 0), every 12th row (indices 11, 23, 35, ...), and the next row (12th, 24th, 36th, ...)\n",
    "rows_to_select = list(range(10, len(data), 12)) + list(range(11, len(data), 12))\n",
    "\n",
    "# Sort the rows (since they might be in an unordered sequence after the concatenation)\n",
    "rows_to_select.sort()\n",
    "\n",
    "# Column index positions: J=9, X=23, Y=24, Z=25, AA=26, AB=27, AD=29\n",
    "columns_to_select = [9, 23, 24, 25, 26, 27, 29]\n",
    "\n",
    "# Select the rows and the specific columns by index\n",
    "cleaned_data = data.iloc[rows_to_select, columns_to_select]\n",
    "\n",
    "# Display the cleaned data to double check\n",
    "print(cleaned_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping Data for the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patch pick1_team1 pick2_team1   pick3_team1 pick4_team1 pick5_team1  \\\n",
      "0  13.24     Kalista       Senna       Orianna      Maokai      Aatrox   \n",
      "1  13.24       Neeko    Bel'Veth        Kennen       Senna  Tahm Kench   \n",
      "2  13.24       Neeko     Caitlyn           Lux         Jax    Bel'Veth   \n",
      "3  13.24      Rumble      Draven  Renata Glasc    Tristana   Jarvan IV   \n",
      "4  13.24       Varus        Azir      Nautilus    Xin Zhao    Renekton   \n",
      "\n",
      "    pick1_team2   pick2_team2 pick3_team2 pick4_team2 pick5_team2  result  \n",
      "0  Renata Glasc         Varus     LeBlanc        Rell      Rumble       1  \n",
      "1       Kalista           Jax     LeBlanc        Rell   Jarvan IV       1  \n",
      "2       Kalista  Renata Glasc        Azir     Lee Sin      Aatrox       0  \n",
      "3       Orianna       Kalista       Senna      Aatrox      Wukong       0  \n",
      "4         Milio       Orianna      Lucian     Lee Sin      Aatrox       0  \n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "data_grouped = []\n",
    "for i in range(0, len(cleaned_data), 2):\n",
    "    # Combine the features of the two rows (picks, patch, etc.) into one row\n",
    "    patch = cleaned_data.iloc[i, 0]  # Get the patch from the first row of the pair (index 0 is the patch column)\n",
    "    \n",
    "    # Combine picks for both teams (pick1-pick5) and the patch\n",
    "    row = [patch] + cleaned_data.iloc[i, 1:6].tolist() + cleaned_data.iloc[i+1, 1:6].tolist()\n",
    "    \n",
    "    # Append result from the second row of the pair (team 1's result)\n",
    "    row.append(cleaned_data.iloc[i+1, -1])  # Assuming result is the last column\n",
    "    \n",
    "    data_grouped.append(row)\n",
    "\n",
    "# Convert the list of grouped data into a new DataFrame\n",
    "columns = ['patch', 'pick1_team1', 'pick2_team1', 'pick3_team1', 'pick4_team1', 'pick5_team1',\n",
    "           'pick1_team2', 'pick2_team2', 'pick3_team2', 'pick4_team2', 'pick5_team2', 'result']\n",
    "\n",
    "game_data = pd.DataFrame(data_grouped, columns=columns)\n",
    "\n",
    "# Convert all columns to strings\n",
    "game_data = game_data.astype(str)\n",
    "\n",
    "# Convert result to an integer\n",
    "game_data['result'] = game_data['result'].astype(int)\n",
    "\n",
    "# Display the first few rows of the grouped data\n",
    "print(game_data.head())\n",
    "print(game_data['result'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch                 14.01\n",
      "pick1_team1         LeBlanc\n",
      "pick2_team1           Varus\n",
      "pick3_team1    Renata Glasc\n",
      "pick4_team1        Renekton\n",
      "pick5_team1        Xin Zhao\n",
      "pick1_team2         Kalista\n",
      "pick2_team2           Neeko\n",
      "pick3_team2         Lee Sin\n",
      "pick4_team2        Nautilus\n",
      "pick5_team2             Jax\n",
      "result                    0\n",
      "Name: 15, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure it correctly aligned the patch numbers\n",
    "first_game_patch_14_01 = game_data[game_data['patch'] == '14.01'].iloc[0]\n",
    "print(first_game_patch_14_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "In general, models in machine learning do not want to take strings as inputs, so categorical variables should be encoded. \n",
    "\\\n",
    "There are many methods of encoding, but this model will be using one-hot encoding for the patches and multi-hot encoding for each team's draft.\n",
    "\n",
    "\n",
    "**A Short Explanation**\n",
    "\n",
    "In one-hot encoding, a variable is converted into a binary vector, where each element represents a different category.\n",
    "\n",
    "For example, say a variable `animal` can take on three possible values: `\"cat\"`, `\"dog\"`, or `\"bird\"`. \\\n",
    "Since there are three values, the one-hot vector would have three elements, and suppose that the first element represents `\"cat\"`, the second `\"dog\"`, and the last `\"bird\"`. \\\n",
    "Then every time there is a data point that is a `\"cat\"`, it would be encoded by the vector `[1, 0, 0]`. Similarly, `\"dog\"` would be encoded by `[0, 1, 0]`, and `[0, 0, 1]` for `\"bird\"`.\n",
    "\n",
    "Multi-hot encoding works similarly, except a vector may contain more than one `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patch pick1_team1 pick2_team1   pick3_team1 pick4_team1 pick5_team1  \\\n",
      "0  13.24     Kalista       Senna       Orianna      Maokai      Aatrox   \n",
      "1  13.24       Neeko    Bel'Veth        Kennen       Senna  Tahm Kench   \n",
      "2  13.24       Neeko     Caitlyn           Lux         Jax    Bel'Veth   \n",
      "3  13.24      Rumble      Draven  Renata Glasc    Tristana   Jarvan IV   \n",
      "4  13.24       Varus        Azir      Nautilus    Xin Zhao    Renekton   \n",
      "\n",
      "    pick1_team2   pick2_team2 pick3_team2 pick4_team2  ... patch_14.14  \\\n",
      "0  Renata Glasc         Varus     LeBlanc        Rell  ...           0   \n",
      "1       Kalista           Jax     LeBlanc        Rell  ...           0   \n",
      "2       Kalista  Renata Glasc        Azir     Lee Sin  ...           0   \n",
      "3       Orianna       Kalista       Senna      Aatrox  ...           0   \n",
      "4         Milio       Orianna      Lucian     Lee Sin  ...           0   \n",
      "\n",
      "   patch_14.15  patch_14.16  patch_14.17  patch_14.18  patch_14.19  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   patch_14.2  patch_14.21  patch_14.22  patch_nan  \n",
      "0           0            0            0          0  \n",
      "1           0            0            0          0  \n",
      "2           0            0            0          0  \n",
      "3           0            0            0          0  \n",
      "4           0            0            0          0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_patches = pd.get_dummies(game_data['patch'], prefix='patch')\n",
    "\n",
    "one_hot_encoded_patches = one_hot_encoded_patches.astype(int)\n",
    "\n",
    "# Add the encoded patches back to the original DataFrame\n",
    "game_data = pd.concat([game_data, one_hot_encoded_patches], axis=1)\n",
    "\n",
    "print(game_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        team1_vector  \\\n",
      "0  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, ...   \n",
      "3  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                        team2_vector  \n",
      "0  [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
      "1  [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, ...  \n",
      "2  [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "# Identify all unique champions across all picks\n",
    "champions = pd.unique(game_data[['pick1_team1', 'pick2_team1', 'pick3_team1', 'pick4_team1', 'pick5_team1',\n",
    "                                 'pick1_team2', 'pick2_team2', 'pick3_team2', 'pick4_team2', 'pick5_team2']].values.ravel())\n",
    "\n",
    "# Create a mapping from champion name to index\n",
    "champion_to_index = {champ: idx for idx, champ in enumerate(champions)}\n",
    "\n",
    "# Create multi-hot encoding for each team\n",
    "def create_multi_hot_vector(picks, champion_to_index, num_champions):\n",
    "    vector = np.zeros(num_champions, dtype=int)\n",
    "    for pick in picks:\n",
    "        if pick in champion_to_index:  # Ignore invalid picks (e.g., NaN)\n",
    "            vector[champion_to_index[pick]] = 1\n",
    "    return vector\n",
    "\n",
    "# Apply multi-hot encoding to the dataset\n",
    "num_champions = len(champions)\n",
    "\n",
    "team1_vectors = []\n",
    "team2_vectors = []\n",
    "\n",
    "for _, row in game_data.iterrows():\n",
    "    team1_picks = row[['pick1_team1', 'pick2_team1', 'pick3_team1', 'pick4_team1', 'pick5_team1']]\n",
    "    team2_picks = row[['pick1_team2', 'pick2_team2', 'pick3_team2', 'pick4_team2', 'pick5_team2']]\n",
    "    \n",
    "    team1_vectors.append(create_multi_hot_vector(team1_picks, champion_to_index, num_champions))\n",
    "    team2_vectors.append(create_multi_hot_vector(team2_picks, champion_to_index, num_champions))\n",
    "\n",
    "# Add the multi-hot vectors to the DataFrame\n",
    "game_data['team1_vector'] = team1_vectors\n",
    "game_data['team2_vector'] = team2_vectors\n",
    "\n",
    "print(game_data[['team1_vector', 'team2_vector']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([7751, 360])\n",
      "y_train_tensor shape: torch.Size([7751, 1])\n",
      "X_test_tensor shape: torch.Size([1938, 360])\n",
      "y_test_tensor shape: torch.Size([1938, 1])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate features as before\n",
    "patch_columns = [col for col in game_data.columns if col.startswith('patch_')]\n",
    "patch_encoded = game_data[patch_columns].values \n",
    "team1_vectors = np.array(game_data['team1_vector'].tolist())\n",
    "team2_vectors = np.array(game_data['team2_vector'].tolist())\n",
    "X = np.hstack([patch_encoded, team1_vectors, team2_vectors])\n",
    "y = game_data['result'].values\n",
    "\n",
    "# Randomly shuffle and split the data\n",
    "np.random.seed(42)  # Set the random seed for reproducibility\n",
    "indices = np.random.permutation(len(X))\n",
    "split_index = int(0.8 * len(X))\n",
    "\n",
    "train_indices = indices[:split_index]\n",
    "test_indices = indices[split_index:]\n",
    "\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Verify\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")\n",
    "print(f\"X_test_tensor shape: {X_test_tensor.shape}\")\n",
    "print(f\"y_test_tensor shape: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeagueDraftPredictor(\n",
      "  (fc1): Linear(in_features=360, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeagueDraftPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LeagueDraftPredictor, self).__init__()\n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # Input layer to first hidden layer\n",
    "        self.fc2 = nn.Linear(512, 512)          # First hidden layer to second hidden layer\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)            # Second hidden layer to output\n",
    "        self.dropout = nn.Dropout(0.3)         # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))              # First hidden layer with ReLU\n",
    "        x = self.dropout(x)                  # Apply dropout\n",
    "        x = F.relu(self.fc2(x))              # Second hidden layer with ReLU\n",
    "        x = self.dropout(x)                  # Apply dropout\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc4(x))       # Sigmoid activation for binary classification\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_train_tensor.shape[1]  # Number of input features\n",
    "model = LeagueDraftPredictor(input_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.6908\n",
      "Epoch 2/50, Loss: 0.6763\n",
      "Epoch 3/50, Loss: 0.6388\n",
      "Epoch 4/50, Loss: 0.5531\n",
      "Epoch 5/50, Loss: 0.4225\n",
      "Epoch 6/50, Loss: 0.3126\n",
      "Epoch 7/50, Loss: 0.2589\n",
      "Epoch 8/50, Loss: 0.2056\n",
      "Epoch 9/50, Loss: 0.1774\n",
      "Epoch 10/50, Loss: 0.1692\n",
      "Epoch 11/50, Loss: 0.1493\n",
      "Epoch 12/50, Loss: 0.1430\n",
      "Epoch 13/50, Loss: 0.1318\n",
      "Epoch 14/50, Loss: 0.1223\n",
      "Epoch 15/50, Loss: 0.1203\n",
      "Epoch 16/50, Loss: 0.1172\n",
      "Epoch 17/50, Loss: 0.1115\n",
      "Epoch 18/50, Loss: 0.1141\n",
      "Epoch 19/50, Loss: 0.1080\n",
      "Epoch 20/50, Loss: 0.1072\n",
      "Epoch 21/50, Loss: 0.1062\n",
      "Epoch 22/50, Loss: 0.0967\n",
      "Epoch 23/50, Loss: 0.1026\n",
      "Epoch 24/50, Loss: 0.1021\n",
      "Epoch 25/50, Loss: 0.0934\n",
      "Epoch 26/50, Loss: 0.0964\n",
      "Epoch 27/50, Loss: 0.0961\n",
      "Epoch 28/50, Loss: 0.0926\n",
      "Epoch 29/50, Loss: 0.0934\n",
      "Epoch 30/50, Loss: 0.0891\n",
      "Epoch 31/50, Loss: 0.0947\n",
      "Epoch 32/50, Loss: 0.0940\n",
      "Epoch 33/50, Loss: 0.0862\n",
      "Epoch 34/50, Loss: 0.0908\n",
      "Epoch 35/50, Loss: 0.0914\n",
      "Epoch 36/50, Loss: 0.0838\n",
      "Epoch 37/50, Loss: 0.0862\n",
      "Epoch 38/50, Loss: 0.0889\n",
      "Epoch 39/50, Loss: 0.0914\n",
      "Epoch 40/50, Loss: 0.0906\n",
      "Epoch 41/50, Loss: 0.0806\n",
      "Epoch 42/50, Loss: 0.0876\n",
      "Epoch 43/50, Loss: 0.0895\n",
      "Epoch 44/50, Loss: 0.0855\n",
      "Epoch 45/50, Loss: 0.0862\n",
      "Epoch 46/50, Loss: 0.0835\n",
      "Epoch 47/50, Loss: 0.0829\n",
      "Epoch 48/50, Loss: 0.0862\n",
      "Epoch 49/50, Loss: 0.0844\n",
      "Epoch 50/50, Loss: 0.0769\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# DataLoader for batching\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()          # Clear gradients from the previous step\n",
    "        outputs = model(batch_X)       # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "        loss.backward()                # Backpropagation\n",
    "        optimizer.step()               # Update weights\n",
    "        epoch_loss += loss.item()      # Accumulate loss\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5299\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)  # Forward pass\n",
    "    test_predictions = (test_outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    accuracy = (test_predictions == y_test_tensor).float().mean().item()  # Compute accuracy\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this model has an accuracy of about 53%, which is acceptable considering it does not factor in team strength. For reference, champions in League of Legends are usually heavily nerfed if they are sitting at a 53-54% winrate, so this model is off to a good start.\n",
    "\n",
    "However, it can definitely be improved, so embeddings will be used next to replace multi-hot encoding for hopefully better representation of the intracacies in drafts, potentially factoring in things such as the synergy between champions and what each champion is good at.\n",
    "\n",
    "**What are embeddings?**\n",
    "\n",
    "Embeddings are a method of representing categorical data for ML models to use, similar to n-hot encoding. However, instead of simply representing data through binary vectors, embeddings use vectors in a low-dimensional space to place objects closer together the more related they are.\n",
    "\n",
    "For example, in n-hot encoding, apples, apple pie, and oranges would all be represented differently through binary vectors, and the model would have no way of telling which foods were more closely related. However, embeddings would allow the model to calculate the \"distance\" between apples and apple pie, and find that they are more closely related than apples and oranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model 2**\n",
    "\n",
    "### Mapping Champions to Indices\n",
    "\n",
    "**Creating a new dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patch pick1_team1 pick2_team1   pick3_team1 pick4_team1 pick5_team1  \\\n",
      "0  13.24     Kalista       Senna       Orianna      Maokai      Aatrox   \n",
      "1  13.24       Neeko    Bel'Veth        Kennen       Senna  Tahm Kench   \n",
      "2  13.24       Neeko     Caitlyn           Lux         Jax    Bel'Veth   \n",
      "3  13.24      Rumble      Draven  Renata Glasc    Tristana   Jarvan IV   \n",
      "4  13.24       Varus        Azir      Nautilus    Xin Zhao    Renekton   \n",
      "\n",
      "    pick1_team2   pick2_team2 pick3_team2 pick4_team2  ... patch_14.14  \\\n",
      "0  Renata Glasc         Varus     LeBlanc        Rell  ...           0   \n",
      "1       Kalista           Jax     LeBlanc        Rell  ...           0   \n",
      "2       Kalista  Renata Glasc        Azir     Lee Sin  ...           0   \n",
      "3       Orianna       Kalista       Senna      Aatrox  ...           0   \n",
      "4         Milio       Orianna      Lucian     Lee Sin  ...           0   \n",
      "\n",
      "   patch_14.15  patch_14.16  patch_14.17  patch_14.18  patch_14.19  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   patch_14.2  patch_14.21  patch_14.22  patch_nan  \n",
      "0           0            0            0          0  \n",
      "1           0            0            0          0  \n",
      "2           0            0            0          0  \n",
      "3           0            0            0          0  \n",
      "4           0            0            0          0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv(r'C:\\Users\\Josh\\Downloads\\2024_LoL_esports_match_data_from_OraclesElixir.csv', low_memory=False)\n",
    "rows_to_select = list(range(10, len(data2), 12)) + list(range(11, len(data2), 12))\n",
    "rows_to_select.sort()\n",
    "columns_to_select = [9, 23, 24, 25, 26, 27, 29]\n",
    "cleaned_data2 = data2.iloc[rows_to_select, columns_to_select]\n",
    "\n",
    "data_grouped2 = []\n",
    "for i in range(0, len(cleaned_data2), 2):\n",
    "    patch = cleaned_data2.iloc[i, 0]\n",
    "    row = [patch] + cleaned_data2.iloc[i, 1:6].tolist() + cleaned_data2.iloc[i + 1, 1:6].tolist()\n",
    "    row.append(cleaned_data2.iloc[i + 1, -1])\n",
    "    data_grouped2.append(row)\n",
    "\n",
    "columns = ['patch', 'pick1_team1', 'pick2_team1', 'pick3_team1', 'pick4_team1', 'pick5_team1',\n",
    "           'pick1_team2', 'pick2_team2', 'pick3_team2', 'pick4_team2', 'pick5_team2', 'result']\n",
    "game_data2 = pd.DataFrame(data_grouped2, columns=columns)\n",
    "game_data2 = game_data2.astype(str)\n",
    "game_data2['result'] = game_data2['result'].astype(int)\n",
    "\n",
    "one_hot_encoded_patches2 = pd.get_dummies(game_data2['patch'], prefix='patch')\n",
    "one_hot_encoded_patches2 = one_hot_encoded_patches2.astype(int)\n",
    "game_data2 = pd.concat([game_data2, one_hot_encoded_patches2], axis=1)\n",
    "\n",
    "print(game_data2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champion to Index Mapping:\n",
      "{'Kalista': 0, 'Senna': 1, 'Orianna': 2, 'Maokai': 3, 'Aatrox': 4, 'Renata Glasc': 5, 'Varus': 6, 'LeBlanc': 7, 'Rell': 8, 'Rumble': 9, 'Neeko': 10, \"Bel'Veth\": 11, 'Kennen': 12, 'Tahm Kench': 13, 'Jax': 14, 'Jarvan IV': 15, 'Caitlyn': 16, 'Lux': 17, 'Azir': 18, 'Lee Sin': 19, 'Draven': 20, 'Tristana': 21, 'Wukong': 22, 'Nautilus': 23, 'Xin Zhao': 24, 'Renekton': 25, 'Milio': 26, 'Lucian': 27, 'Poppy': 28, 'Xayah': 29, 'Rakan': 30, 'Ryze': 31, 'Nocturne': 32, 'Zeri': 33, 'Lulu': 34, 'Nami': 35, 'Akali': 36, 'Sejuani': 37, 'Gragas': 38, 'Sylas': 39, 'Nidalee': 40, \"K'Sante\": 41, 'Vi': 42, 'Ashe': 43, \"Kha'Zix\": 44, 'Ezreal': 45, 'Braum': 46, 'Karthus': 47, 'Jhin': 48, 'Elise': 49, 'Syndra': 50, 'Jayce': 51, 'Viego': 52, 'Cassiopeia': 53, 'Malphite': 54, 'Veigar': 55, 'nan': 56, 'Taliyah': 57, 'Leona': 58, 'Ornn': 59, 'Aphelios': 60, 'Ziggs': 61, 'Briar': 62, \"Vel'Koz\": 63, \"Kai'Sa\": 64, 'Gwen': 65, 'Yone': 66, 'Blitzcrank': 67, 'Hwei': 68, 'Alistar': 69, 'Fiora': 70, 'Irelia': 71, 'Heimerdinger': 72, 'Brand': 73, 'Talon': 74, 'Olaf': 75, 'Karma': 76, 'Ahri': 77, 'Twisted Fate': 78, 'Trundle': 79, 'Ivern': 80, 'Bard': 81, 'Sion': 82, 'Pyke': 83, 'Graves': 84, 'Garen': 85, 'Xerath': 86, 'Gnar': 87, 'Malzahar': 88, 'Camille': 89, 'Volibear': 90, 'Lillia': 91, 'Riven': 92, 'Sett': 93, 'Vladimir': 94, 'Rengar': 95, 'Corki': 96, 'Udyr': 97, 'Jinx': 98, 'Nilah': 99, 'Shen': 100, \"Kog'Maw\": 101, 'Swain': 102, 'Aurelion Sol': 103, 'Yuumi': 104, 'Soraka': 105, 'Galio': 106, 'Zac': 107, 'Zyra': 108, 'Mordekaiser': 109, 'Darius': 110, 'Kayle': 111, 'Miss Fortune': 112, 'Sivir': 113, 'Amumu': 114, 'Seraphine': 115, 'Yasuo': 116, 'Viktor': 117, 'Janna': 118, 'Sona': 119, 'Taric': 120, 'Kindred': 121, 'Samira': 122, 'Twitch': 123, 'Vayne': 124, 'Kled': 125, 'Kassadin': 126, 'Evelynn': 127, 'Vex': 128, 'Gangplank': 129, 'Dr. Mundo': 130, 'Tryndamere': 131, 'Thresh': 132, 'Lissandra': 133, 'Pantheon': 134, 'Akshan': 135, 'Fiddlesticks': 136, 'Diana': 137, 'Rammus': 138, 'Morgana': 139, 'Kayn': 140, 'Naafiri': 141, \"Cho'Gath\": 142, 'Ekko': 143, 'Annie': 144, 'Zoe': 145, 'Urgot': 146, 'Singed': 147, 'Illaoi': 148, 'Smolder': 149, 'Zilean': 150, 'Zed': 151, 'Nasus': 152, 'Shyvana': 153, 'Nunu & Willump': 154, 'Warwick': 155, 'Katarina': 156, 'Skarner': 157, 'Teemo': 158, 'Shaco': 159, 'Fizz': 160, 'Quinn': 161, \"Rek'Sai\": 162, 'Yorick': 163, 'Anivia': 164, 'Hecarim': 165, 'Qiyana': 166, 'Aurora': 167}\n",
      "Index for a specific champion 'Aatrox': 4\n",
      "Total champions mapped: 168\n"
     ]
    }
   ],
   "source": [
    "# Extract all champion names from the pick columns in game_data2\n",
    "pick_columns = ['pick1_team1', 'pick2_team1', 'pick3_team1', 'pick4_team1', 'pick5_team1',\n",
    "                'pick1_team2', 'pick2_team2', 'pick3_team2', 'pick4_team2', 'pick5_team2']\n",
    "\n",
    "unique_champions = pd.unique(game_data2[pick_columns].values.ravel())  # Get all unique champion names\n",
    "champion_to_index = {champ: idx for idx, champ in enumerate(unique_champions)}  # Map champions to indices\n",
    "\n",
    "# Add this mapping to the game_data2 DataFrame for reference (optional)\n",
    "game_data2['champion_to_index_mapping'] = str(champion_to_index)\n",
    "\n",
    "# Display the mapping\n",
    "print(\"Champion to Index Mapping:\")\n",
    "print(champion_to_index)\n",
    "\n",
    "print(f\"Index for a specific champion 'Aatrox': {champion_to_index.get('Aatrox', 'Not Found')}\")\n",
    "print(f\"Total champions mapped: {len(champion_to_index)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with champion indices:\n",
      "   pick1_team1  pick2_team1  pick3_team1  pick4_team1  pick5_team1  \\\n",
      "0            0            1            2            3            4   \n",
      "1           10           11           12            1           13   \n",
      "2           10           16           17           14           11   \n",
      "3            9           20            5           21           15   \n",
      "4            6           18           23           24           25   \n",
      "\n",
      "   pick1_team2  pick2_team2  pick3_team2  pick4_team2  pick5_team2  \n",
      "0            5            6            7            8            9  \n",
      "1            0           14            7            8           15  \n",
      "2            0            5           18           19            4  \n",
      "3            2            0            1            4           22  \n",
      "4           26            2           27           19            4  \n"
     ]
    }
   ],
   "source": [
    "# Replace champion names in the pick columns with their indices\n",
    "for col in pick_columns:\n",
    "    game_data2[col] = game_data2[col].map(champion_to_index)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Data with champion indices:\")\n",
    "print(game_data2[pick_columns].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 1 picks train tensor shape: torch.Size([7751, 5])\n",
      "Team 2 picks train tensor shape: torch.Size([7751, 5])\n",
      "Patches train tensor shape: torch.Size([7751, 24])\n",
      "Result train tensor shape: torch.Size([7751, 1])\n",
      "Team 1 picks test tensor shape: torch.Size([1938, 5])\n",
      "Team 2 picks test tensor shape: torch.Size([1938, 5])\n",
      "Patches test tensor shape: torch.Size([1938, 24])\n",
      "Result test tensor shape: torch.Size([1938, 1])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare inputs (separate picks and results)\n",
    "X_picks_team1 = game_data2[['pick1_team1', 'pick2_team1', 'pick3_team1', 'pick4_team1', 'pick5_team1']].values\n",
    "X_picks_team2 = game_data2[['pick1_team2', 'pick2_team2', 'pick3_team2', 'pick4_team2', 'pick5_team2']].values\n",
    "X_patches = game_data2[one_hot_encoded_patches2.columns].values\n",
    "y = game_data2['result'].values\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (80/20 split)\n",
    "X_picks_team1_train, X_picks_team1_test, X_picks_team2_train, X_picks_team2_test, X_patches_train, X_patches_test, y_train, y_test = train_test_split(\n",
    "    X_picks_team1, X_picks_team2, X_patches, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Convert to PyTorch tensors\n",
    "X_picks_team1_train_tensor = torch.tensor(X_picks_team1_train, dtype=torch.long)\n",
    "X_picks_team2_train_tensor = torch.tensor(X_picks_team2_train, dtype=torch.long)\n",
    "X_patches_train_tensor = torch.tensor(X_patches_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Ensure y is 2D for binary classification\n",
    "\n",
    "X_picks_team1_test_tensor = torch.tensor(X_picks_team1_test, dtype=torch.long)\n",
    "X_picks_team2_test_tensor = torch.tensor(X_picks_team2_test, dtype=torch.long)\n",
    "X_patches_test_tensor = torch.tensor(X_patches_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Step 4: Verify the shapes of the tensors\n",
    "print(f\"Team 1 picks train tensor shape: {X_picks_team1_train_tensor.shape}\")\n",
    "print(f\"Team 2 picks train tensor shape: {X_picks_team2_train_tensor.shape}\")\n",
    "print(f\"Patches train tensor shape: {X_patches_train_tensor.shape}\")\n",
    "print(f\"Result train tensor shape: {y_train_tensor.shape}\")\n",
    "\n",
    "print(f\"Team 1 picks test tensor shape: {X_picks_team1_test_tensor.shape}\")\n",
    "print(f\"Team 2 picks test tensor shape: {X_picks_team2_test_tensor.shape}\")\n",
    "print(f\"Patches test tensor shape: {X_patches_test_tensor.shape}\")\n",
    "print(f\"Result test tensor shape: {y_test_tensor.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeagueDraftEmbeddingsModel(\n",
      "  (embedding): Embedding(168, 16)\n",
      "  (fc1): Linear(in_features=56, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeagueDraftEmbeddingsModel(nn.Module):\n",
    "    def __init__(self, num_champions, patch_input_size, embedding_dim=16):\n",
    "        super(LeagueDraftEmbeddingsModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer for champions picks (team 1 and team 2)\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_champions, embedding_dim=embedding_dim)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim + patch_input_size, 128)  # Input: 2*embedding_dim + patch_input_size\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  \n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout for regularization\n",
    "\n",
    "    def forward(self, team1_picks, team2_picks, patch_features):\n",
    "        # Average the embeddings of team picks\n",
    "        team1_embedded = self.embedding(team1_picks).mean(dim=1)  # Average the embeddings for team 1\n",
    "        team2_embedded = self.embedding(team2_picks).mean(dim=1)  # Average the embeddings for team 2\n",
    "\n",
    "        # Concatenate the averaged embeddings of both teams and patch features\n",
    "        combined_features = torch.cat([team1_embedded, team2_embedded, patch_features], dim=1)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        x = F.relu(self.fc1(combined_features))  # First hidden layer with ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = F.relu(self.fc2(x))  # Second hidden layer with ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "\n",
    "        # Final sigmoid layer for binary classification (0 or 1)\n",
    "        x = torch.sigmoid(self.fc3(x))  # Output layer\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "num_champions = len(champion_to_idx)  # Number of unique champions\n",
    "patch_input_size = len(one_hot_encoded_patches2.columns)  # Number of patch features (after one-hot encoding)\n",
    "embedding_dim = 16  # You can experiment with this value\n",
    "\n",
    "model = LeagueDraftEmbeddingsModel(num_champions, patch_input_size, embedding_dim)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6915, Accuracy: 53.39%\n",
      "Epoch 2/100, Loss: 0.6882, Accuracy: 54.61%\n",
      "Epoch 3/100, Loss: 0.6842, Accuracy: 55.71%\n",
      "Epoch 4/100, Loss: 0.6790, Accuracy: 56.34%\n",
      "Epoch 5/100, Loss: 0.6729, Accuracy: 58.46%\n",
      "Epoch 6/100, Loss: 0.6686, Accuracy: 58.99%\n",
      "Epoch 7/100, Loss: 0.6641, Accuracy: 59.21%\n",
      "Epoch 8/100, Loss: 0.6552, Accuracy: 59.95%\n",
      "Epoch 9/100, Loss: 0.6485, Accuracy: 61.23%\n",
      "Epoch 10/100, Loss: 0.6437, Accuracy: 62.73%\n",
      "Epoch 11/100, Loss: 0.6322, Accuracy: 63.60%\n",
      "Epoch 12/100, Loss: 0.6252, Accuracy: 64.26%\n",
      "Epoch 13/100, Loss: 0.6172, Accuracy: 65.55%\n",
      "Epoch 14/100, Loss: 0.6101, Accuracy: 65.88%\n",
      "Epoch 15/100, Loss: 0.6039, Accuracy: 66.29%\n",
      "Epoch 16/100, Loss: 0.6012, Accuracy: 67.64%\n",
      "Epoch 17/100, Loss: 0.5921, Accuracy: 67.94%\n",
      "Epoch 18/100, Loss: 0.5831, Accuracy: 68.52%\n",
      "Epoch 19/100, Loss: 0.5818, Accuracy: 67.86%\n",
      "Epoch 20/100, Loss: 0.5734, Accuracy: 69.60%\n",
      "Epoch 21/100, Loss: 0.5580, Accuracy: 70.13%\n",
      "Epoch 22/100, Loss: 0.5564, Accuracy: 70.97%\n",
      "Epoch 23/100, Loss: 0.5510, Accuracy: 70.96%\n",
      "Epoch 24/100, Loss: 0.5389, Accuracy: 71.56%\n",
      "Epoch 25/100, Loss: 0.5393, Accuracy: 71.69%\n",
      "Epoch 26/100, Loss: 0.5304, Accuracy: 72.06%\n",
      "Epoch 27/100, Loss: 0.5280, Accuracy: 72.53%\n",
      "Epoch 28/100, Loss: 0.5166, Accuracy: 73.26%\n",
      "Epoch 29/100, Loss: 0.5207, Accuracy: 72.57%\n",
      "Epoch 30/100, Loss: 0.5139, Accuracy: 73.90%\n",
      "Epoch 31/100, Loss: 0.5117, Accuracy: 73.44%\n",
      "Epoch 32/100, Loss: 0.5037, Accuracy: 73.91%\n",
      "Epoch 33/100, Loss: 0.4939, Accuracy: 74.66%\n",
      "Epoch 34/100, Loss: 0.4975, Accuracy: 74.66%\n",
      "Epoch 35/100, Loss: 0.4918, Accuracy: 74.87%\n",
      "Epoch 36/100, Loss: 0.4842, Accuracy: 75.33%\n",
      "Epoch 37/100, Loss: 0.4837, Accuracy: 75.05%\n",
      "Epoch 38/100, Loss: 0.4860, Accuracy: 75.02%\n",
      "Epoch 39/100, Loss: 0.4813, Accuracy: 75.56%\n",
      "Epoch 40/100, Loss: 0.4685, Accuracy: 75.72%\n",
      "Epoch 41/100, Loss: 0.4653, Accuracy: 76.61%\n",
      "Epoch 42/100, Loss: 0.4591, Accuracy: 76.83%\n",
      "Epoch 43/100, Loss: 0.4581, Accuracy: 77.06%\n",
      "Epoch 44/100, Loss: 0.4568, Accuracy: 77.46%\n",
      "Epoch 45/100, Loss: 0.4518, Accuracy: 77.16%\n",
      "Epoch 46/100, Loss: 0.4476, Accuracy: 78.02%\n",
      "Epoch 47/100, Loss: 0.4462, Accuracy: 77.82%\n",
      "Epoch 48/100, Loss: 0.4451, Accuracy: 77.67%\n",
      "Epoch 49/100, Loss: 0.4325, Accuracy: 78.73%\n",
      "Epoch 50/100, Loss: 0.4394, Accuracy: 78.20%\n",
      "Epoch 51/100, Loss: 0.4330, Accuracy: 78.56%\n",
      "Epoch 52/100, Loss: 0.4321, Accuracy: 78.62%\n",
      "Epoch 53/100, Loss: 0.4176, Accuracy: 78.62%\n",
      "Epoch 54/100, Loss: 0.4256, Accuracy: 78.96%\n",
      "Epoch 55/100, Loss: 0.4305, Accuracy: 78.75%\n",
      "Epoch 56/100, Loss: 0.4212, Accuracy: 79.27%\n",
      "Epoch 57/100, Loss: 0.4208, Accuracy: 79.24%\n",
      "Epoch 58/100, Loss: 0.4155, Accuracy: 79.63%\n",
      "Epoch 59/100, Loss: 0.4060, Accuracy: 80.16%\n",
      "Epoch 60/100, Loss: 0.4187, Accuracy: 79.11%\n",
      "Epoch 61/100, Loss: 0.4163, Accuracy: 79.81%\n",
      "Epoch 62/100, Loss: 0.4014, Accuracy: 80.34%\n",
      "Epoch 63/100, Loss: 0.4004, Accuracy: 80.13%\n",
      "Epoch 64/100, Loss: 0.3937, Accuracy: 80.89%\n",
      "Epoch 65/100, Loss: 0.3985, Accuracy: 80.40%\n",
      "Epoch 66/100, Loss: 0.3908, Accuracy: 80.93%\n",
      "Epoch 67/100, Loss: 0.4064, Accuracy: 80.17%\n",
      "Epoch 68/100, Loss: 0.3950, Accuracy: 80.89%\n",
      "Epoch 69/100, Loss: 0.3960, Accuracy: 81.14%\n",
      "Epoch 70/100, Loss: 0.3882, Accuracy: 81.45%\n",
      "Epoch 71/100, Loss: 0.3848, Accuracy: 81.54%\n",
      "Epoch 72/100, Loss: 0.3835, Accuracy: 81.06%\n",
      "Epoch 73/100, Loss: 0.3852, Accuracy: 81.65%\n",
      "Epoch 74/100, Loss: 0.3827, Accuracy: 81.63%\n",
      "Epoch 75/100, Loss: 0.3790, Accuracy: 81.45%\n",
      "Epoch 76/100, Loss: 0.3742, Accuracy: 81.98%\n",
      "Epoch 77/100, Loss: 0.3752, Accuracy: 81.63%\n",
      "Epoch 78/100, Loss: 0.3706, Accuracy: 82.18%\n",
      "Epoch 79/100, Loss: 0.3764, Accuracy: 81.95%\n",
      "Epoch 80/100, Loss: 0.3728, Accuracy: 82.32%\n",
      "Epoch 81/100, Loss: 0.3778, Accuracy: 81.85%\n",
      "Epoch 82/100, Loss: 0.3745, Accuracy: 81.74%\n",
      "Epoch 83/100, Loss: 0.3633, Accuracy: 82.47%\n",
      "Epoch 84/100, Loss: 0.3637, Accuracy: 82.29%\n",
      "Epoch 85/100, Loss: 0.3631, Accuracy: 82.97%\n",
      "Epoch 86/100, Loss: 0.3548, Accuracy: 83.41%\n",
      "Epoch 87/100, Loss: 0.3618, Accuracy: 82.70%\n",
      "Epoch 88/100, Loss: 0.3629, Accuracy: 82.91%\n",
      "Epoch 89/100, Loss: 0.3588, Accuracy: 82.89%\n",
      "Epoch 90/100, Loss: 0.3635, Accuracy: 82.60%\n",
      "Epoch 91/100, Loss: 0.3525, Accuracy: 83.34%\n",
      "Epoch 92/100, Loss: 0.3562, Accuracy: 83.63%\n",
      "Epoch 93/100, Loss: 0.3472, Accuracy: 83.72%\n",
      "Epoch 94/100, Loss: 0.3452, Accuracy: 83.51%\n",
      "Epoch 95/100, Loss: 0.3488, Accuracy: 83.47%\n",
      "Epoch 96/100, Loss: 0.3469, Accuracy: 83.40%\n",
      "Epoch 97/100, Loss: 0.3518, Accuracy: 83.74%\n",
      "Epoch 98/100, Loss: 0.3481, Accuracy: 83.54%\n",
      "Epoch 99/100, Loss: 0.3388, Accuracy: 83.91%\n",
      "Epoch 100/100, Loss: 0.3401, Accuracy: 84.31%\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Step 1: Prepare the dataset and DataLoader for training\n",
    "train_dataset = TensorDataset(X_picks_team1_train_tensor, X_picks_team2_train_tensor, X_patches_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Step 2: Define the model and instantiate it\n",
    "model = LeagueDraftEmbeddingsModel(num_champions=len(champion_to_idx), patch_input_size=patch_input_size, embedding_dim=16)\n",
    "\n",
    "# Step 3: Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Step 4: Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch_X1, batch_X2, batch_patch, batch_y in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients from the previous step\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X1, batch_X2, batch_patch)  # Get predictions\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, batch_y)  # Ensure y is the correct shape for BCELoss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        # Calculate the number of correct predictions\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == batch_y).sum().item()\n",
    "        total_predictions += batch_y.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Calculate accuracy for the epoch\n",
    "    accuracy = 100 * correct_predictions / total_predictions\n",
    "\n",
    "    # Print loss and accuracy for the current epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
